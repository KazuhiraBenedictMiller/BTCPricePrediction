{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04fefed6-9e25-49c8-bcb7-42b1c99e2606",
   "metadata": {},
   "source": [
    "# Creating the Model for our Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "376c05a9-b2c6-401c-b7f8-8cc88628ef46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#For our Predictions we'll be Using a LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd79c201-d827-4ceb-b3a5-b335cbd946c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ed5df-4752-4965-b78f-634f0aed511c",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ce900a3-ec77-4b0a-a5ce-a65f7023bbab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, train_test_split as TTS, GridSearchCV as GCV, TimeSeriesSplit as TSS\n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "import ntplib\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../scripts/\")\n",
    "\n",
    "import path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2b84f9-bdbc-45e8-9b49-85460e44d559",
   "metadata": {},
   "source": [
    "# Importing Features Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbb61dc0-4fa9-4df2-bf97-af048be2c97c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_336_Hours_Ago</th>\n",
       "      <th>Close_335_Hours_Ago</th>\n",
       "      <th>Close_334_Hours_Ago</th>\n",
       "      <th>Close_333_Hours_Ago</th>\n",
       "      <th>Close_332_Hours_Ago</th>\n",
       "      <th>Close_331_Hours_Ago</th>\n",
       "      <th>Close_330_Hours_Ago</th>\n",
       "      <th>Close_329_Hours_Ago</th>\n",
       "      <th>Close_328_Hours_Ago</th>\n",
       "      <th>Close_327_Hours_Ago</th>\n",
       "      <th>...</th>\n",
       "      <th>Close_8_Hours_Ago</th>\n",
       "      <th>Close_7_Hours_Ago</th>\n",
       "      <th>Close_6_Hours_Ago</th>\n",
       "      <th>Close_5_Hours_Ago</th>\n",
       "      <th>Close_4_Hours_Ago</th>\n",
       "      <th>Close_3_Hours_Ago</th>\n",
       "      <th>Close_2_Hours_Ago</th>\n",
       "      <th>Close_1_Hours_Ago</th>\n",
       "      <th>ActualClose</th>\n",
       "      <th>ActualDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47022.75</td>\n",
       "      <td>46889.47</td>\n",
       "      <td>47052.39</td>\n",
       "      <td>46977.81</td>\n",
       "      <td>47017.01</td>\n",
       "      <td>46709.76</td>\n",
       "      <td>46689.60</td>\n",
       "      <td>47009.70</td>\n",
       "      <td>47478.33</td>\n",
       "      <td>46847.85</td>\n",
       "      <td>...</td>\n",
       "      <td>51492.41</td>\n",
       "      <td>51886.65</td>\n",
       "      <td>51714.12</td>\n",
       "      <td>51218.06</td>\n",
       "      <td>51258.94</td>\n",
       "      <td>50991.45</td>\n",
       "      <td>51039.92</td>\n",
       "      <td>50717.77</td>\n",
       "      <td>50369.39</td>\n",
       "      <td>2021-12-28 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46889.47</td>\n",
       "      <td>47052.39</td>\n",
       "      <td>46977.81</td>\n",
       "      <td>47017.01</td>\n",
       "      <td>46709.76</td>\n",
       "      <td>46689.60</td>\n",
       "      <td>47009.70</td>\n",
       "      <td>47478.33</td>\n",
       "      <td>46847.85</td>\n",
       "      <td>47365.26</td>\n",
       "      <td>...</td>\n",
       "      <td>51886.65</td>\n",
       "      <td>51714.12</td>\n",
       "      <td>51218.06</td>\n",
       "      <td>51258.94</td>\n",
       "      <td>50991.45</td>\n",
       "      <td>51039.92</td>\n",
       "      <td>50717.77</td>\n",
       "      <td>50369.39</td>\n",
       "      <td>49838.69</td>\n",
       "      <td>2021-12-28 01:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47052.39</td>\n",
       "      <td>46977.81</td>\n",
       "      <td>47017.01</td>\n",
       "      <td>46709.76</td>\n",
       "      <td>46689.60</td>\n",
       "      <td>47009.70</td>\n",
       "      <td>47478.33</td>\n",
       "      <td>46847.85</td>\n",
       "      <td>47365.26</td>\n",
       "      <td>47628.67</td>\n",
       "      <td>...</td>\n",
       "      <td>51714.12</td>\n",
       "      <td>51218.06</td>\n",
       "      <td>51258.94</td>\n",
       "      <td>50991.45</td>\n",
       "      <td>51039.92</td>\n",
       "      <td>50717.77</td>\n",
       "      <td>50369.39</td>\n",
       "      <td>49838.69</td>\n",
       "      <td>49794.92</td>\n",
       "      <td>2021-12-28 02:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46977.81</td>\n",
       "      <td>47017.01</td>\n",
       "      <td>46709.76</td>\n",
       "      <td>46689.60</td>\n",
       "      <td>47009.70</td>\n",
       "      <td>47478.33</td>\n",
       "      <td>46847.85</td>\n",
       "      <td>47365.26</td>\n",
       "      <td>47628.67</td>\n",
       "      <td>47526.00</td>\n",
       "      <td>...</td>\n",
       "      <td>51218.06</td>\n",
       "      <td>51258.94</td>\n",
       "      <td>50991.45</td>\n",
       "      <td>51039.92</td>\n",
       "      <td>50717.77</td>\n",
       "      <td>50369.39</td>\n",
       "      <td>49838.69</td>\n",
       "      <td>49794.92</td>\n",
       "      <td>49843.51</td>\n",
       "      <td>2021-12-28 03:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47017.01</td>\n",
       "      <td>46709.76</td>\n",
       "      <td>46689.60</td>\n",
       "      <td>47009.70</td>\n",
       "      <td>47478.33</td>\n",
       "      <td>46847.85</td>\n",
       "      <td>47365.26</td>\n",
       "      <td>47628.67</td>\n",
       "      <td>47526.00</td>\n",
       "      <td>47180.14</td>\n",
       "      <td>...</td>\n",
       "      <td>51258.94</td>\n",
       "      <td>50991.45</td>\n",
       "      <td>51039.92</td>\n",
       "      <td>50717.77</td>\n",
       "      <td>50369.39</td>\n",
       "      <td>49838.69</td>\n",
       "      <td>49794.92</td>\n",
       "      <td>49843.51</td>\n",
       "      <td>49077.57</td>\n",
       "      <td>2021-12-28 04:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17827</th>\n",
       "      <td>42099.94</td>\n",
       "      <td>42122.45</td>\n",
       "      <td>42337.53</td>\n",
       "      <td>42471.06</td>\n",
       "      <td>42515.53</td>\n",
       "      <td>42355.70</td>\n",
       "      <td>42459.92</td>\n",
       "      <td>42232.84</td>\n",
       "      <td>42242.60</td>\n",
       "      <td>42297.37</td>\n",
       "      <td>...</td>\n",
       "      <td>46643.78</td>\n",
       "      <td>46193.87</td>\n",
       "      <td>46858.17</td>\n",
       "      <td>46574.36</td>\n",
       "      <td>46876.36</td>\n",
       "      <td>46921.73</td>\n",
       "      <td>46738.77</td>\n",
       "      <td>46657.29</td>\n",
       "      <td>46890.10</td>\n",
       "      <td>2024-01-09 19:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17828</th>\n",
       "      <td>42122.45</td>\n",
       "      <td>42337.53</td>\n",
       "      <td>42471.06</td>\n",
       "      <td>42515.53</td>\n",
       "      <td>42355.70</td>\n",
       "      <td>42459.92</td>\n",
       "      <td>42232.84</td>\n",
       "      <td>42242.60</td>\n",
       "      <td>42297.37</td>\n",
       "      <td>42454.83</td>\n",
       "      <td>...</td>\n",
       "      <td>46193.87</td>\n",
       "      <td>46858.17</td>\n",
       "      <td>46574.36</td>\n",
       "      <td>46876.36</td>\n",
       "      <td>46921.73</td>\n",
       "      <td>46738.77</td>\n",
       "      <td>46657.29</td>\n",
       "      <td>46890.10</td>\n",
       "      <td>46651.31</td>\n",
       "      <td>2024-01-09 20:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17829</th>\n",
       "      <td>42337.53</td>\n",
       "      <td>42471.06</td>\n",
       "      <td>42515.53</td>\n",
       "      <td>42355.70</td>\n",
       "      <td>42459.92</td>\n",
       "      <td>42232.84</td>\n",
       "      <td>42242.60</td>\n",
       "      <td>42297.37</td>\n",
       "      <td>42454.83</td>\n",
       "      <td>42425.66</td>\n",
       "      <td>...</td>\n",
       "      <td>46858.17</td>\n",
       "      <td>46574.36</td>\n",
       "      <td>46876.36</td>\n",
       "      <td>46921.73</td>\n",
       "      <td>46738.77</td>\n",
       "      <td>46657.29</td>\n",
       "      <td>46890.10</td>\n",
       "      <td>46651.31</td>\n",
       "      <td>45419.45</td>\n",
       "      <td>2024-01-09 21:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17830</th>\n",
       "      <td>42471.06</td>\n",
       "      <td>42515.53</td>\n",
       "      <td>42355.70</td>\n",
       "      <td>42459.92</td>\n",
       "      <td>42232.84</td>\n",
       "      <td>42242.60</td>\n",
       "      <td>42297.37</td>\n",
       "      <td>42454.83</td>\n",
       "      <td>42425.66</td>\n",
       "      <td>42467.26</td>\n",
       "      <td>...</td>\n",
       "      <td>46574.36</td>\n",
       "      <td>46876.36</td>\n",
       "      <td>46921.73</td>\n",
       "      <td>46738.77</td>\n",
       "      <td>46657.29</td>\n",
       "      <td>46890.10</td>\n",
       "      <td>46651.31</td>\n",
       "      <td>45419.45</td>\n",
       "      <td>46278.06</td>\n",
       "      <td>2024-01-09 22:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17831</th>\n",
       "      <td>42515.53</td>\n",
       "      <td>42355.70</td>\n",
       "      <td>42459.92</td>\n",
       "      <td>42232.84</td>\n",
       "      <td>42242.60</td>\n",
       "      <td>42297.37</td>\n",
       "      <td>42454.83</td>\n",
       "      <td>42425.66</td>\n",
       "      <td>42467.26</td>\n",
       "      <td>42716.33</td>\n",
       "      <td>...</td>\n",
       "      <td>46876.36</td>\n",
       "      <td>46921.73</td>\n",
       "      <td>46738.77</td>\n",
       "      <td>46657.29</td>\n",
       "      <td>46890.10</td>\n",
       "      <td>46651.31</td>\n",
       "      <td>45419.45</td>\n",
       "      <td>46278.06</td>\n",
       "      <td>46124.08</td>\n",
       "      <td>2024-01-09 23:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17832 rows × 338 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Close_336_Hours_Ago  Close_335_Hours_Ago  Close_334_Hours_Ago  \\\n",
       "0                 47022.75             46889.47             47052.39   \n",
       "1                 46889.47             47052.39             46977.81   \n",
       "2                 47052.39             46977.81             47017.01   \n",
       "3                 46977.81             47017.01             46709.76   \n",
       "4                 47017.01             46709.76             46689.60   \n",
       "...                    ...                  ...                  ...   \n",
       "17827             42099.94             42122.45             42337.53   \n",
       "17828             42122.45             42337.53             42471.06   \n",
       "17829             42337.53             42471.06             42515.53   \n",
       "17830             42471.06             42515.53             42355.70   \n",
       "17831             42515.53             42355.70             42459.92   \n",
       "\n",
       "       Close_333_Hours_Ago  Close_332_Hours_Ago  Close_331_Hours_Ago  \\\n",
       "0                 46977.81             47017.01             46709.76   \n",
       "1                 47017.01             46709.76             46689.60   \n",
       "2                 46709.76             46689.60             47009.70   \n",
       "3                 46689.60             47009.70             47478.33   \n",
       "4                 47009.70             47478.33             46847.85   \n",
       "...                    ...                  ...                  ...   \n",
       "17827             42471.06             42515.53             42355.70   \n",
       "17828             42515.53             42355.70             42459.92   \n",
       "17829             42355.70             42459.92             42232.84   \n",
       "17830             42459.92             42232.84             42242.60   \n",
       "17831             42232.84             42242.60             42297.37   \n",
       "\n",
       "       Close_330_Hours_Ago  Close_329_Hours_Ago  Close_328_Hours_Ago  \\\n",
       "0                 46689.60             47009.70             47478.33   \n",
       "1                 47009.70             47478.33             46847.85   \n",
       "2                 47478.33             46847.85             47365.26   \n",
       "3                 46847.85             47365.26             47628.67   \n",
       "4                 47365.26             47628.67             47526.00   \n",
       "...                    ...                  ...                  ...   \n",
       "17827             42459.92             42232.84             42242.60   \n",
       "17828             42232.84             42242.60             42297.37   \n",
       "17829             42242.60             42297.37             42454.83   \n",
       "17830             42297.37             42454.83             42425.66   \n",
       "17831             42454.83             42425.66             42467.26   \n",
       "\n",
       "       Close_327_Hours_Ago  ...  Close_8_Hours_Ago  Close_7_Hours_Ago  \\\n",
       "0                 46847.85  ...           51492.41           51886.65   \n",
       "1                 47365.26  ...           51886.65           51714.12   \n",
       "2                 47628.67  ...           51714.12           51218.06   \n",
       "3                 47526.00  ...           51218.06           51258.94   \n",
       "4                 47180.14  ...           51258.94           50991.45   \n",
       "...                    ...  ...                ...                ...   \n",
       "17827             42297.37  ...           46643.78           46193.87   \n",
       "17828             42454.83  ...           46193.87           46858.17   \n",
       "17829             42425.66  ...           46858.17           46574.36   \n",
       "17830             42467.26  ...           46574.36           46876.36   \n",
       "17831             42716.33  ...           46876.36           46921.73   \n",
       "\n",
       "       Close_6_Hours_Ago  Close_5_Hours_Ago  Close_4_Hours_Ago  \\\n",
       "0               51714.12           51218.06           51258.94   \n",
       "1               51218.06           51258.94           50991.45   \n",
       "2               51258.94           50991.45           51039.92   \n",
       "3               50991.45           51039.92           50717.77   \n",
       "4               51039.92           50717.77           50369.39   \n",
       "...                  ...                ...                ...   \n",
       "17827           46858.17           46574.36           46876.36   \n",
       "17828           46574.36           46876.36           46921.73   \n",
       "17829           46876.36           46921.73           46738.77   \n",
       "17830           46921.73           46738.77           46657.29   \n",
       "17831           46738.77           46657.29           46890.10   \n",
       "\n",
       "       Close_3_Hours_Ago  Close_2_Hours_Ago  Close_1_Hours_Ago  ActualClose  \\\n",
       "0               50991.45           51039.92           50717.77     50369.39   \n",
       "1               51039.92           50717.77           50369.39     49838.69   \n",
       "2               50717.77           50369.39           49838.69     49794.92   \n",
       "3               50369.39           49838.69           49794.92     49843.51   \n",
       "4               49838.69           49794.92           49843.51     49077.57   \n",
       "...                  ...                ...                ...          ...   \n",
       "17827           46921.73           46738.77           46657.29     46890.10   \n",
       "17828           46738.77           46657.29           46890.10     46651.31   \n",
       "17829           46657.29           46890.10           46651.31     45419.45   \n",
       "17830           46890.10           46651.31           45419.45     46278.06   \n",
       "17831           46651.31           45419.45           46278.06     46124.08   \n",
       "\n",
       "                     ActualDate  \n",
       "0     2021-12-28 00:00:00+00:00  \n",
       "1     2021-12-28 01:00:00+00:00  \n",
       "2     2021-12-28 02:00:00+00:00  \n",
       "3     2021-12-28 03:00:00+00:00  \n",
       "4     2021-12-28 04:00:00+00:00  \n",
       "...                         ...  \n",
       "17827 2024-01-09 19:00:00+00:00  \n",
       "17828 2024-01-09 20:00:00+00:00  \n",
       "17829 2024-01-09 21:00:00+00:00  \n",
       "17830 2024-01-09 22:00:00+00:00  \n",
       "17831 2024-01-09 23:00:00+00:00  \n",
       "\n",
       "[17832 rows x 338 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FeaturesTargets = pd.read_parquet(path.FEATURES_DATA_DIR / \"BTC-USD_FeaturesData_From2021-12-14 00:00:00+00:00_To2024-01-09 23:00:00+00:00.parquet\")\n",
    "FeaturesTargets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6276657-0d61-4005-bb33-cbd089c9d5c3",
   "metadata": {},
   "source": [
    "# Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95a1afe5-8788-496a-a36f-1e6e1f08d625",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTrain.shape = (14265, 336)\n",
      "yTrain.shape = (14265,)\n",
      "xTest.shape = (3567, 336)\n",
      "yTest.shape = (3567,)\n"
     ]
    }
   ],
   "source": [
    "Features = np.array(FeaturesTargets.drop([\"ActualClose\", \"ActualDate\"], axis=1, inplace=False))\n",
    "Targets = np.array(FeaturesTargets[\"ActualClose\"])\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = TTS(Features, Targets, test_size=0.2)\n",
    "\n",
    "print(f\"{xTrain.shape = }\")\n",
    "print(f\"{yTrain.shape = }\")\n",
    "print(f\"{xTest.shape = }\")\n",
    "print(f\"{yTest.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a30fcbf-ec85-450b-9521-b88bed21b302",
   "metadata": {},
   "source": [
    "# Scaling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86ad834f-6bae-449b-8670-8233e1c402f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Scaler = SS()\n",
    "\n",
    "ScaledxTrain = Scaler.fit_transform(xTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ccd24-2669-4336-baa7-b6b927125407",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating the Model and searching for Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b8671f-6810-4c3e-b661-067a2b51a672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "#Given a Set of Hyperparameters it Trains a Model and Computes an Avg Validation Error Based on TimeSeriesSplit\n",
    "\n",
    "def Objective(T:optuna.trial.Trial) -> float:\n",
    "    \n",
    "    Hyperparams = {\"metric\":\"mae\",\n",
    "                   \"verbose\":-1,\n",
    "                   \"num_leaves\":T.suggest_int(\"num_leaves\", 2, 256),\n",
    "                   \"feature_fraction\":T.suggest_float(\"feature_fraction\", 0.2, 1.0),\n",
    "                   \"bagging_fraction\":T.suggest_float(\"bagging_fraction\", 0.2, 1.0),\n",
    "                   \"min_child_samples\":T.suggest_int(\"min_child_samples\", 3, 100),\n",
    "                  }\n",
    "    \n",
    "    tss = TSS(n_splits=2)\n",
    "    Scores = []\n",
    "    \n",
    "    for trainIndex, valIndex in tss.split(ScaledxTrain):\n",
    "        \n",
    "        #Split Data for Training and Validation\n",
    "        xTrain_, xVal_ = ScaledxTrain[trainIndex, :], ScaledxTrain[valIndex, :]\n",
    "        yTrain_, yVal_ = yTrain[trainIndex], yTrain[valIndex]\n",
    "        \n",
    "        #Train the Model\n",
    "        LGB = lgb.LGBMRegressor(**Hyperparams)\n",
    "        LGB.fit(xTrain_, yTrain_)\n",
    "        \n",
    "        #Evaluate the Model\n",
    "        yPred = LGB.predict(xVal_)\n",
    "        mae = MAE(yVal_, yPred)\n",
    "        \n",
    "        Scores.append(mae)\n",
    "        \n",
    "    #Return Avg Score\n",
    "    return np.array(Scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76a10891-9c41-4e83-9615-0de8e7f08a02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-16 14:14:37,618] A new study created in memory with name: no-name-2d33cc33-b2f2-4119-ab23-cb6bf19e0ee0\n",
      "[I 2024-01-16 14:14:59,626] Trial 0 finished with value: 123.04068849142773 and parameters: {'num_leaves': 239, 'feature_fraction': 0.8052265999042525, 'bagging_fraction': 0.33311487892502545, 'min_child_samples': 86}. Best is trial 0 with value: 123.04068849142773.\n",
      "[I 2024-01-16 14:15:12,849] Trial 1 finished with value: 120.17991878429811 and parameters: {'num_leaves': 153, 'feature_fraction': 0.4550515204765634, 'bagging_fraction': 0.6417867018947867, 'min_child_samples': 56}. Best is trial 1 with value: 120.17991878429811.\n",
      "[I 2024-01-16 14:15:21,060] Trial 2 finished with value: 123.81168723881595 and parameters: {'num_leaves': 78, 'feature_fraction': 0.49111933548545494, 'bagging_fraction': 0.850438174614248, 'min_child_samples': 90}. Best is trial 1 with value: 120.17991878429811.\n",
      "[I 2024-01-16 14:15:24,563] Trial 3 finished with value: 138.6885165283109 and parameters: {'num_leaves': 34, 'feature_fraction': 0.2173938226031547, 'bagging_fraction': 0.3181615087958856, 'min_child_samples': 63}. Best is trial 1 with value: 120.17991878429811.\n",
      "[I 2024-01-16 14:15:32,746] Trial 4 finished with value: 122.00781781412692 and parameters: {'num_leaves': 39, 'feature_fraction': 0.6834518098107905, 'bagging_fraction': 0.6527646705473935, 'min_child_samples': 83}. Best is trial 1 with value: 120.17991878429811.\n"
     ]
    }
   ],
   "source": [
    "Study = optuna.create_study(direction=\"minimize\")\n",
    "Study.optimize(Objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68efd887-93fe-4bb7-bf23-65a1b3dd233c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 153,\n",
       " 'feature_fraction': 0.4550515204765634,\n",
       " 'bagging_fraction': 0.6417867018947867,\n",
       " 'min_child_samples': 56}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BestParams = Study.best_trial.params\n",
    "BestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd073cad-7450-46c9-9d0a-c8af3c45145d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.4550515204765634, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4550515204765634\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6417867018947867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6417867018947867\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4550515204765634, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4550515204765634\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6417867018947867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6417867018947867\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 85680\n",
      "[LightGBM] [Info] Number of data points in the train set: 14265, number of used features: 336\n",
      "[LightGBM] [Info] Start training from score 28828.090965\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(bagging_fraction=0.6417867018947867,\n",
       "              feature_fraction=0.4550515204765634, min_child_samples=56,\n",
       "              num_leaves=153)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(bagging_fraction=0.6417867018947867,\n",
       "              feature_fraction=0.4550515204765634, min_child_samples=56,\n",
       "              num_leaves=153)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.6417867018947867,\n",
       "              feature_fraction=0.4550515204765634, min_child_samples=56,\n",
       "              num_leaves=153)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BestModel = lgb.LGBMRegressor(**BestParams)\n",
    "BestModel.fit(ScaledxTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cdf6bed-7dad-4f69-baf3-d8703979f69c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.4550515204765634, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4550515204765634\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6417867018947867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6417867018947867\n",
      "testMae = 109.8613\n"
     ]
    }
   ],
   "source": [
    "Preds = BestModel.predict(Scaler.transform(xTest))\n",
    "testMae = MAE(yTest, Preds)\n",
    "print(f\"{testMae = :.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d13c961-4187-402a-9476-91ab7f994825",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dumping Model and Scaler to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98a75594-572d-49a5-b866-e7bc734367e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/Zero/Scrivania/btcpricepredictionvenv/model/Scaler.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(BestModel, path.MODEL_DIR / \"Model.pkl\")\n",
    "joblib.dump(Scaler, path.MODEL_DIR / \"Scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef54b5f4-075e-45ee-9758-89d1345606de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Initialize LGBMRegressor estimattor\\nLGB = lgb.LGBMRegressor(objective='regression')\\n\\n\\nparam_grid = {\\n         'verbose': [-1],\\n         'num_leaves': [x for x in range(64, 257, 12)],\\n         'feature_fraction': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\\n         'bagging_fraction': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\\n         'min_child_samples': [x for x in range(3, 101, 4)]\\n    }\\n\\n#Initialize Grid Search with 3-fold cross validation \\nModel = GCV(estimator=LGB, \\n                     param_grid=param_grid,\\n                     cv=3, \\n                     n_jobs=-1, \\n                     scoring='neg_mean_absolute_error',\\n                     verbose=10)\\n\\nModel.fit(ScaledxTrain, yTrain)\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOT ENOUGH LOCAL COMPUTING POWER TO SUPPORT THIS\n",
    "\n",
    "'''\n",
    "#Initialize LGBMRegressor estimattor\n",
    "LGB = lgb.LGBMRegressor(objective='regression')\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "         'verbose': [-1],\n",
    "         'num_leaves': [x for x in range(64, 257, 12)],\n",
    "         'feature_fraction': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "         'bagging_fraction': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "         'min_child_samples': [x for x in range(3, 101, 4)]\n",
    "    }\n",
    "\n",
    "#Initialize Grid Search with 3-fold cross validation \n",
    "Model = GCV(estimator=LGB, \n",
    "                     param_grid=param_grid,\n",
    "                     cv=3, \n",
    "                     n_jobs=-1, \n",
    "                     scoring='neg_mean_absolute_error',\n",
    "                     verbose=10)\n",
    "\n",
    "Model.fit(ScaledxTrain, yTrain)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btcpricepredictionvenv",
   "language": "python",
   "name": "btcpricepredictionvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
